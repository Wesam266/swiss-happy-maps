{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module gets the dataframe with id, sentiment, canton for instagram json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import folium\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import json\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "spark_path = os.environ[\"SPARK_PATH\"]\n",
    "os.environ['SPARK_HOME'] = spark_path\n",
    "os.environ['HADOOP_HOME'] = spark_path\n",
    "\n",
    "sys.path.append(spark_path + \"/bin\")\n",
    "sys.path.append(spark_path + \"/python\")\n",
    "sys.path.append(spark_path + \"/python/pyspark/\")\n",
    "sys.path.append(spark_path + \"/python/lib\")\n",
    "sys.path.append(spark_path + \"/python/lib/pyspark.zip\")\n",
    "sys.path.append(spark_path + \"/python/lib/py4j-0.9-src.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "import fnmatch\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# Defining sc\n",
    "conf = SparkConf().setAppName(\"ADA-GCL\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# use SQL context\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Application\n",
    "\n",
    "Quite simple at the moment, just getting the dataframe. \n",
    "Started running at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Path definitions\n",
    "sample_path ='hdfs://iccluster046.iccluster.epfl.ch:8020/datasets/goodcitylife/april/harvest3r_instagram_data_28-04_0.json'\n",
    "base_path = 'hdfs://iccluster046.iccluster.epfl.ch:8020/datasets/goodcitylife'\n",
    "insta_files='*/harvest3r_instagram_data*.json'\n",
    "\n",
    "# getting the dataframe\n",
    "# sdf = sqlContext.read.json(sample_path)\n",
    "\n",
    "# Get all files under a particular directory\n",
    "def get_paths(dir_path, recurse):\n",
    "    t = []\n",
    "    files = []\n",
    "    if(recurse == True):\n",
    "        cat = subprocess.Popen([\"hadoop\", \"fs\", \"-ls\", \"-R\", dir_path], stdout=subprocess.PIPE)\n",
    "    else:\n",
    "        cat = subprocess.Popen([\"hadoop\", \"fs\", \"-ls\", dir_path], stdout=subprocess.PIPE)\n",
    "    for line in cat.stdout:\n",
    "        t.append(line.decode())\n",
    "        \n",
    "    for l in t[1:]:\n",
    "        files.append(l.split(' ')[-1].rstrip())\n",
    "    return(files)\n",
    "\n",
    "# getting just the relevant paths, in this case just the Instagram ones.\n",
    "file_list = []\n",
    "all_paths = get_paths(base_path, True)\n",
    "for path in all_paths:\n",
    "    if(fnmatch.fnmatch(path, insta_files)):\n",
    "        file_list.append(path)\n",
    "\n",
    "# do the operation for all the files\n",
    "sdf_list = []\n",
    "for file_path in file_list:\n",
    "    sdf_list.append(sqlContext.read.json(file_path))\n",
    "\n",
    "\n",
    "# Displays the content of the DataFrame to stdout\n",
    "# sdf.show()\n",
    "print(len(sdf_list))\n",
    "\n",
    "# convert dataframe to pandas\n",
    "# df = sdf.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Operations\n",
    "* will need to move this into Spark Applications with Spark DataFrames, but developing locally using pandas DataFrames now..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a good canton list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geo_map = {'city':['zurich','geneva','lausanne','zermatt','bern','basel','geneve','winterthur','luzern','lucerne','st-gallen','lugano'], \n",
    "           'canton': ['Zurich', 'Geneva','Vaud', 'Valais', \"Bern\", 'Basel-City', 'Geneva', 'Zurich', 'Lucerne','Lucerne', 'St-Gallen', 'Ticino']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_geo = pd.DataFrame.from_dict(geo_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canton</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zurich</td>\n",
       "      <td>zurich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geneva</td>\n",
       "      <td>geneva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vaud</td>\n",
       "      <td>lausanne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Valais</td>\n",
       "      <td>zermatt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bern</td>\n",
       "      <td>bern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   canton      city\n",
       "0  Zurich    zurich\n",
       "1  Geneva    geneva\n",
       "2    Vaud  lausanne\n",
       "3  Valais   zermatt\n",
       "4    Bern      bern"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_population = ['zurich','geneva','lausanne','zermatt','bern','basel','geneve','winterthur','luzern','lucerne','st-gallen','lugano','biel','thun','fribourg']\n",
    "top_tourist = ['zermatt','montreux','jungfrau','interlaken',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popular_cities = ['zurich','geneva','lausanne','zermatt','bern','basel','geneve','winterthur','luzern','lusern','st-gallen','lugano']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['zurich', 'geneva', 'lausanne', 'zermatt', 'bern', 'basel',\n",
       "       'geneve', 'winterthur', 'luzern', 'lucerne', 'st-gallen', 'lugano'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geo.city.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Cantons\n",
    "Downloaded an Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Municipality</th>\n",
       "      <th>Canton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aadorf</td>\n",
       "      <td>Aadorf</td>\n",
       "      <td>TG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aarau</td>\n",
       "      <td>Aarau</td>\n",
       "      <td>AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aarau Rohr</td>\n",
       "      <td>Aarau</td>\n",
       "      <td>AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aarberg</td>\n",
       "      <td>Aarberg</td>\n",
       "      <td>BE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aarburg</td>\n",
       "      <td>Aarburg</td>\n",
       "      <td>AG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City Municipality Canton\n",
       "0      Aadorf       Aadorf     TG\n",
       "1       Aarau        Aarau     AG\n",
       "3  Aarau Rohr        Aarau     AG\n",
       "4     Aarberg      Aarberg     BE\n",
       "5     Aarburg      Aarburg     AG"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cantons = pd.read_csv('cities_cantons.csv')\n",
    "df_cantons = df_cantons[['Ortschaftsname','Gemeindename','Kantonsk√ºrzel']].drop_duplicates()\n",
    "df_cantons.columns = ['City','Municipality','Canton']\n",
    "df_cantons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe with Geo and Sentiment\n",
    "* 1) turning the raw dataframe with id, index, score, source and type into a dataframe with id, tags, and sentiment\n",
    "* 2) turn the list of geo_id into one new column with just one geolocation\n",
    "* 3) map that geolocation to another column called canton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Original DataFrame\n",
    "read from Spark Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_json('Sample Data/harvest3r_instagram_data_15-04_0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>_index</th>\n",
       "      <th>_score</th>\n",
       "      <th>_source</th>\n",
       "      <th>_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1460752286000003072</td>\n",
       "      <td>merged_content_2016_04_15_to_2016_04_21</td>\n",
       "      <td>0.048309</td>\n",
       "      <td>{'main_format': 'TEXT', 'author_name': 'Fabio ...</td>\n",
       "      <td>content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1460727556000007168</td>\n",
       "      <td>merged_content_2016_04_15_to_2016_04_21</td>\n",
       "      <td>0.029747</td>\n",
       "      <td>{'main_format': 'TEXT', 'author_name': 'MiRO',...</td>\n",
       "      <td>content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1460728673000006656</td>\n",
       "      <td>merged_content_2016_04_15_to_2016_04_21</td>\n",
       "      <td>0.026873</td>\n",
       "      <td>{'main_format': 'TEXT', 'sentiment': 'NEUTRAL'...</td>\n",
       "      <td>content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1460749002000007168</td>\n",
       "      <td>merged_content_2016_04_15_to_2016_04_21</td>\n",
       "      <td>0.022194</td>\n",
       "      <td>{'main_format': 'TEXT', 'sentiment': 'POSITIVE...</td>\n",
       "      <td>content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1460742655000008960</td>\n",
       "      <td>merged_content_2016_04_15_to_2016_04_21</td>\n",
       "      <td>0.021687</td>\n",
       "      <td>{'main_format': 'TEXT', 'sentiment': 'POSITIVE...</td>\n",
       "      <td>content</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   _id                                   _index    _score  \\\n",
       "0  1460752286000003072  merged_content_2016_04_15_to_2016_04_21  0.048309   \n",
       "1  1460727556000007168  merged_content_2016_04_15_to_2016_04_21  0.029747   \n",
       "2  1460728673000006656  merged_content_2016_04_15_to_2016_04_21  0.026873   \n",
       "3  1460749002000007168  merged_content_2016_04_15_to_2016_04_21  0.022194   \n",
       "4  1460742655000008960  merged_content_2016_04_15_to_2016_04_21  0.021687   \n",
       "\n",
       "                                             _source    _type  \n",
       "0  {'main_format': 'TEXT', 'author_name': 'Fabio ...  content  \n",
       "1  {'main_format': 'TEXT', 'author_name': 'MiRO',...  content  \n",
       "2  {'main_format': 'TEXT', 'sentiment': 'NEUTRAL'...  content  \n",
       "3  {'main_format': 'TEXT', 'sentiment': 'POSITIVE...  content  \n",
       "4  {'main_format': 'TEXT', 'sentiment': 'POSITIVE...  content  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Getting id, tags, sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tags(source):\n",
    "    return source['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentiment(source):\n",
    "    return source.get('sentiment') # getting the value from key using dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sentiment = df._source.apply(get_sentiment).to_frame('Sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tags = df._source.apply(get_tags).to_frame('Tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_extracted = df._id.to_frame('_id').join(df_sentiment)\n",
    "df_extracted = df_extracted.join(df_tags)\n",
    "df = df_extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning Tags into Categories\n",
    "\n",
    "Ideas: if they are travels, then they are a traveller.\n",
    "- there are some common tags as well\n",
    "- food (food, desert, drinks)\n",
    "- culture (books, movies, music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# returns a list of tags with duplicates removed\n",
    "def tags2list(tag_strings):\n",
    "    tag_list = []\n",
    "    for subcategory in tag_strings:\n",
    "        tag_list.extend(subcategory.split(' #'))\n",
    "    return list(set(tag_list)) #removes duplicates in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "food_tags = [\"food #foodporn #yum #instafood #yummy #amazing #instagood #photooftheday #sweet #dinner #lunch #breakfast #fresh #tasty #food #delish #delicious #eating #foodpic #foodpics #eat #hungry #foodgasm #hot #foods\",\n",
    "            \"dessert #food #desserts #yum #yummy #amazing #instagood #instafood #sweet #chocolate #cake #icecream #dessertporn #delish #foods #delicious #tasty #eat #eating #hungry #foodpics #sweettooth\",\n",
    "            \"drink #drinks #slurp #pub #bar #liquor #yum #yummy #thirst #thirsty #instagood #cocktail #cocktails #drinkup #glass #can #photooftheday #beer #beers #wine\"]\n",
    "\n",
    "culture_tags = [\"movies #theatre #video #movie #film #films #videos #actor #actress #cinema #dvd #amc #instamovies #star #moviestar #photooftheday #hollywood #goodmovie #instagood #flick #flicks #instaflick #instaflicks\",\n",
    "              \"music #genre #song #songs #melody #hiphop #rnb #pop #love #rap #dubstep #instagood #beat #beats #jam #myjam #party #partymusic #newsong #lovethissong #remix #favoritesong #bestsong #photooftheday #bumpin #repeat #listentothis #goodmusic #instamusic\",\n",
    "              \"movies #theatre #video #movie #film #films #videos #actor #actress #cinema #dvd #amc #instamovies #star #moviestar #photooftheday #hollywood #goodmovie #instagood #flick #flicks #instaflick #instaflicks\"]\n",
    "\n",
    "travel_tags = [\"travel #traveling #vacation #visiting #instatravel #instago #instagood #trip #holiday #photooftheday #fun #travelling #tourism #tourist #instapassport #instatraveling #mytravelgram #travelgram #travelingram #igtravel\"]\n",
    "\n",
    "sports_tags = [\"soccer #ball #futbol #futball #kick #pass #shoot #score #goal #field #net #team #soccerball #photooftheday #instafutbol #instagood #grass #run #soccergame #fifa #worldcup\",\n",
    "              \"hockey #hockeystick #puck #ice #rink #icerink #hockeyplayer #instagood #hockeyplayers #fight #photooftheday #shot #skate #hockeygram #stanleycup #score #hockeylife #pucklife #nhl\",\n",
    "              \"football #ball #pass #footballgame #footballseason #footballgames #footballplayer #instagood #pass #jersey #stadium #field #yards #photooftheday #yardline #pads #touchdown #catch #quarterback #fit #grass #nfl #superbowl #kickoff #run\",\n",
    "               \"basketball #basket #ball #baller #hoop #balling #sports #sport #court #net #rim #backboard #instagood #game #photooftheday #active #pass #throw #shoot #instaballer #instaball #jump #nba #bball\",\n",
    "               \"baseball #base #ball #bases #homerun #bat #throw #catch #swing #photooftheday #field #pitcher #mlb #firstbase #game #instagood #secondbase #thirdbase #inning #baseballbat #mitt #gloves #out #sport #sports\",\n",
    "               \"sports #sport #active #fit #football #soccer #basketball #futball #ball #balls #fun #game #games #crowd #fans #play #playing #player #field #green #grass #score #goal #action #kick #throw #pass #win #winning\",]\n",
    "\n",
    "nature_tags = [\"nature #sky #sun #summer #beach #beautiful #pretty #sunset #sunrise #blue #flowers #night #tree #twilight #clouds #beauty #light #cloudporn #photooftheday #love #green #skylovers #dusk #weather #day #red #iphonesia #mothernature\",\n",
    "              \"clouds #cloud #cloudporn #weather #lookup #sky #skies #skyporn #cloudy #instacloud #instaclouds #instagood #nature #beautiful #gloomy #skyline #horizon #overcast #instasky #epicsky #crazyclouds #photooftheday #cloud_skye #skyback #insta_sky_lovers #iskyhub\",\n",
    "               \"fall #autumn #leaves #falltime #season #seasons #instafall #instagood #instaautumn #photooftheday #leaf #foliage #colorful #orange #red #autumnweather #fallweather #nature\",\n",
    "               \"snow #snowing #winter #cold #ice #white #weather #sky #skies #frosty #frost #chilly #nature #snowflakes #instagood #instawinter #instasnow #photooftheday #snowfall #blizzard\",\n",
    "               \"sunset #sunrise #sun #pretty #beautiful #red #orange #pink #sky #skyporn #cloudporn #nature #clouds #horizon #photooftheday #instagood #gorgeous #warm #view #night #morning #silhouette #instasky #all_sunsets\",\n",
    "               \"winter #cold #holidays #snow #rain #christmas #snowing #blizzard #snowflakes #wintertime #staywarm #cloudy #instawinter #instagood #holidayseason #photooftheday #season #seasons #nature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "general_tags = ['amazing','fresh','photooftheday','instagood','green','fun','love','blue','red','hot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags_list = [food_tags, culture_tags, travel_tags, sports_tags, nature_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dinner',\n",
       " 'glass',\n",
       " 'cake',\n",
       " 'foodporn',\n",
       " 'desserts',\n",
       " 'dessert',\n",
       " 'pub',\n",
       " 'thirsty',\n",
       " 'foods',\n",
       " 'yum',\n",
       " 'eating',\n",
       " 'delish',\n",
       " 'hungry',\n",
       " 'breakfast',\n",
       " 'foodpic',\n",
       " 'yummy',\n",
       " 'slurp',\n",
       " 'delicious',\n",
       " 'amazing',\n",
       " 'can',\n",
       " 'hot',\n",
       " 'instafood',\n",
       " 'chocolate',\n",
       " 'beer',\n",
       " 'icecream',\n",
       " 'sweettooth',\n",
       " 'drink',\n",
       " 'eat',\n",
       " 'cocktails',\n",
       " 'foodpics',\n",
       " 'dessertporn',\n",
       " 'photooftheday',\n",
       " 'thirst',\n",
       " 'lunch',\n",
       " 'wine',\n",
       " 'foodgasm',\n",
       " 'drinkup',\n",
       " 'tasty',\n",
       " 'sweet',\n",
       " 'beers',\n",
       " 'instagood',\n",
       " 'cocktail',\n",
       " 'drinks',\n",
       " 'bar',\n",
       " 'food',\n",
       " 'fresh',\n",
       " 'liquor']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags2list(food_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# removes duplicates and combines all the tags from subcategories\n",
    "def new_tags_list(tags_list):\n",
    "    new_tags_list = []\n",
    "    for tags in tags_list:\n",
    "        new_tags_list.append(list(set(tags2list(tags)) - set(general_tags)))\n",
    "    return new_tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_tags_list = new_tags_list(tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dinner',\n",
       "  'glass',\n",
       "  'cake',\n",
       "  'foodporn',\n",
       "  'desserts',\n",
       "  'dessert',\n",
       "  'pub',\n",
       "  'thirsty',\n",
       "  'foods',\n",
       "  'yum',\n",
       "  'eating',\n",
       "  'delish',\n",
       "  'hungry',\n",
       "  'breakfast',\n",
       "  'foodpic',\n",
       "  'yummy',\n",
       "  'slurp',\n",
       "  'delicious',\n",
       "  'can',\n",
       "  'hot',\n",
       "  'instafood',\n",
       "  'chocolate',\n",
       "  'beer',\n",
       "  'sweettooth',\n",
       "  'icecream',\n",
       "  'drink',\n",
       "  'eat',\n",
       "  'cocktails',\n",
       "  'foodpics',\n",
       "  'dessertporn',\n",
       "  'thirst',\n",
       "  'lunch',\n",
       "  'wine',\n",
       "  'foodgasm',\n",
       "  'drinkup',\n",
       "  'tasty',\n",
       "  'sweet',\n",
       "  'beers',\n",
       "  'cocktail',\n",
       "  'drinks',\n",
       "  'bar',\n",
       "  'food',\n",
       "  'liquor'],\n",
       " ['dvd',\n",
       "  'lovethissong',\n",
       "  'flicks',\n",
       "  'cinema',\n",
       "  'theatre',\n",
       "  'actor',\n",
       "  'pop',\n",
       "  'favoritesong',\n",
       "  'song',\n",
       "  'genre',\n",
       "  'videos',\n",
       "  'bestsong',\n",
       "  'moviestar',\n",
       "  'music',\n",
       "  'flick',\n",
       "  'rnb',\n",
       "  'bumpin',\n",
       "  'goodmovie',\n",
       "  'amc',\n",
       "  'goodmusic',\n",
       "  'beats',\n",
       "  'party',\n",
       "  'myjam',\n",
       "  'listentothis',\n",
       "  'films',\n",
       "  'movies',\n",
       "  'dubstep',\n",
       "  'instamovies',\n",
       "  'actress',\n",
       "  'hollywood',\n",
       "  'melody',\n",
       "  'rap',\n",
       "  'hiphop',\n",
       "  'star',\n",
       "  'video',\n",
       "  'movie',\n",
       "  'newsong',\n",
       "  'film',\n",
       "  'instaflicks',\n",
       "  'remix',\n",
       "  'songs',\n",
       "  'beat',\n",
       "  'jam',\n",
       "  'partymusic',\n",
       "  'repeat',\n",
       "  'instamusic',\n",
       "  'instaflick'],\n",
       " ['instatravel',\n",
       "  'igtravel',\n",
       "  'instatraveling',\n",
       "  'vacation',\n",
       "  'mytravelgram',\n",
       "  'tourism',\n",
       "  'travelgram',\n",
       "  'instago',\n",
       "  'visiting',\n",
       "  'trip',\n",
       "  'instapassport',\n",
       "  'travel',\n",
       "  'traveling',\n",
       "  'travelling',\n",
       "  'tourist',\n",
       "  'travelingram',\n",
       "  'holiday'],\n",
       " ['firstbase',\n",
       "  'win',\n",
       "  'worldcup',\n",
       "  'bases',\n",
       "  'nfl',\n",
       "  'mitt',\n",
       "  'swing',\n",
       "  'pitcher',\n",
       "  'soccerball',\n",
       "  'bball',\n",
       "  'playing',\n",
       "  'pucklife',\n",
       "  'football',\n",
       "  'catch',\n",
       "  'fifa',\n",
       "  'instafutbol',\n",
       "  'inning',\n",
       "  'player',\n",
       "  'instaballer',\n",
       "  'yards',\n",
       "  'rink',\n",
       "  'footballplayer',\n",
       "  'game',\n",
       "  'stadium',\n",
       "  'futball',\n",
       "  'hockeygram',\n",
       "  'crowd',\n",
       "  'kickoff',\n",
       "  'games',\n",
       "  'baseballbat',\n",
       "  'hockeylife',\n",
       "  'skate',\n",
       "  'hockey',\n",
       "  'baller',\n",
       "  'fit',\n",
       "  'sport',\n",
       "  'stanleycup',\n",
       "  'superbowl',\n",
       "  'out',\n",
       "  'nba',\n",
       "  'pass',\n",
       "  'active',\n",
       "  'net',\n",
       "  'bat',\n",
       "  'pads',\n",
       "  'base',\n",
       "  'throw',\n",
       "  'winning',\n",
       "  'yardline',\n",
       "  'quarterback',\n",
       "  'jersey',\n",
       "  'icerink',\n",
       "  'action',\n",
       "  'puck',\n",
       "  'gloves',\n",
       "  'footballgame',\n",
       "  'basketball',\n",
       "  'team',\n",
       "  'hockeystick',\n",
       "  'baseball',\n",
       "  'court',\n",
       "  'jump',\n",
       "  'balls',\n",
       "  'hoop',\n",
       "  'thirdbase',\n",
       "  'fans',\n",
       "  'mlb',\n",
       "  'hockeyplayers',\n",
       "  'balling',\n",
       "  'fight',\n",
       "  'homerun',\n",
       "  'score',\n",
       "  'ice',\n",
       "  'run',\n",
       "  'grass',\n",
       "  'futbol',\n",
       "  'backboard',\n",
       "  'soccergame',\n",
       "  'ball',\n",
       "  'kick',\n",
       "  'field',\n",
       "  'instaball',\n",
       "  'play',\n",
       "  'basket',\n",
       "  'hockeyplayer',\n",
       "  'rim',\n",
       "  'touchdown',\n",
       "  'shot',\n",
       "  'footballgames',\n",
       "  'sports',\n",
       "  'soccer',\n",
       "  'goal',\n",
       "  'shoot',\n",
       "  'nhl',\n",
       "  'secondbase',\n",
       "  'footballseason'],\n",
       " ['all_sunsets',\n",
       "  'pretty',\n",
       "  'light',\n",
       "  'fall',\n",
       "  'pink',\n",
       "  'holidayseason',\n",
       "  'lookup',\n",
       "  'instaclouds',\n",
       "  'autumn',\n",
       "  'autumnweather',\n",
       "  'holidays',\n",
       "  'season',\n",
       "  'skyporn',\n",
       "  'leaves',\n",
       "  'cloud',\n",
       "  'overcast',\n",
       "  'snow',\n",
       "  'day',\n",
       "  'beautiful',\n",
       "  'leaf',\n",
       "  'tree',\n",
       "  'warm',\n",
       "  'cloud_skye',\n",
       "  'flowers',\n",
       "  'twilight',\n",
       "  'cloudporn',\n",
       "  'wintertime',\n",
       "  'instasnow',\n",
       "  'snowfall',\n",
       "  'crazyclouds',\n",
       "  'iphonesia',\n",
       "  'blizzard',\n",
       "  'cold',\n",
       "  'epicsky',\n",
       "  'sunrise',\n",
       "  'frost',\n",
       "  'night',\n",
       "  'rain',\n",
       "  'staywarm',\n",
       "  'sunset',\n",
       "  'falltime',\n",
       "  'insta_sky_lovers',\n",
       "  'instaautumn',\n",
       "  'christmas',\n",
       "  'view',\n",
       "  'white',\n",
       "  'nature',\n",
       "  'dusk',\n",
       "  'mothernature',\n",
       "  'horizon',\n",
       "  'snowflakes',\n",
       "  'cloudy',\n",
       "  'instacloud',\n",
       "  'instafall',\n",
       "  'sun',\n",
       "  'gloomy',\n",
       "  'morning',\n",
       "  'skylovers',\n",
       "  'summer',\n",
       "  'weather',\n",
       "  'ice',\n",
       "  'iskyhub',\n",
       "  'sky',\n",
       "  'snowing',\n",
       "  'skyline',\n",
       "  'instasky',\n",
       "  'orange',\n",
       "  'fallweather',\n",
       "  'clouds',\n",
       "  'winter',\n",
       "  'skies',\n",
       "  'silhouette',\n",
       "  'beauty',\n",
       "  'gorgeous',\n",
       "  'instawinter',\n",
       "  'seasons',\n",
       "  'colorful',\n",
       "  'skyback',\n",
       "  'frosty',\n",
       "  'foliage',\n",
       "  'chilly',\n",
       "  'beach']]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_set_intersection(pop_tags):\n",
    "    return list(set(orig_tags) - (set(orig_tags) - set(pop_tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_names = ['Food', 'Sports', 'Nature', 'Culture', 'Travel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index in range(len(new_tags_list)):\n",
    "    df[category_names[index]] = df.apply(lambda x: set(x['Tags']) - (set(x['Tags']) - set(new_tags_list[index])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Food</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Nature</th>\n",
       "      <th>Culture</th>\n",
       "      <th>Travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1460752286000003072</td>\n",
       "      <td>None</td>\n",
       "      <td>[Switzerland, ch, genebra, geneve, genf, ginev...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1460727556000007168</td>\n",
       "      <td>None</td>\n",
       "      <td>[art, border, ch, eidgenoss, helvetia, land, m...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1460728673000006656</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>[Wintersport, earnyourturns, flylowgear, jungf...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1460749002000007168</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[bahnhofklatscher, eidgenoss, eidgenosse, eidg...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1460742655000008960</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[Aarau, Austria, Austrija, Basel, Bazel, Bern,...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   _id Sentiment  \\\n",
       "0  1460752286000003072      None   \n",
       "1  1460727556000007168      None   \n",
       "2  1460728673000006656   NEUTRAL   \n",
       "3  1460749002000007168  POSITIVE   \n",
       "4  1460742655000008960  POSITIVE   \n",
       "\n",
       "                                                Tags Food Sports Nature  \\\n",
       "0  [Switzerland, ch, genebra, geneve, genf, ginev...   {}     {}     {}   \n",
       "1  [art, border, ch, eidgenoss, helvetia, land, m...   {}     {}     {}   \n",
       "2  [Wintersport, earnyourturns, flylowgear, jungf...   {}     {}     {}   \n",
       "3  [bahnhofklatscher, eidgenoss, eidgenosse, eidg...   {}     {}     {}   \n",
       "4  [Aarau, Austria, Austrija, Basel, Bazel, Bern,...   {}     {}     {}   \n",
       "\n",
       "  Culture Travel  \n",
       "0      {}     {}  \n",
       "1      {}     {}  \n",
       "2      {}     {}  \n",
       "3      {}     {}  \n",
       "4      {}     {}  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food: 58\n",
      "Sports: 117\n",
      "Nature: 92\n",
      "Culture: 82\n",
      "Travel: 188\n"
     ]
    }
   ],
   "source": [
    "# checking the the number of categories\n",
    "for category in category_names:\n",
    "    print(category + \": \" + str(len(df[df.apply(lambda x: len(x[category]),axis=1) > 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for category in category_names:\n",
    "    df[category] = df[category].map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Food</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Nature</th>\n",
       "      <th>Culture</th>\n",
       "      <th>Travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1460720573000010240</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[and, ataxia, booyah, club, dancefloor, dims, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1460720573000010240</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[and, ataxia, booyah, club, dancefloor, dims, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1460720574000013056</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[and, ataxia, booyah, club, dancefloor, dims, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1460701241000001536</td>\n",
       "      <td>None</td>\n",
       "      <td>[Bar, George, Grill, Restaurant, afterwork, be...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1460742792000012032</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[abstract, actor, architecture, awesome, bouti...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1460757080000015360</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[brennereiclub, captainsclub, dasschwarzeschaf...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1460730835000011008</td>\n",
       "      <td>None</td>\n",
       "      <td>[alps, interlaken, movie, selca, selfie, skydi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1460715627000008192</td>\n",
       "      <td>None</td>\n",
       "      <td>[feelgood, fridaymorning, keeponrunning, lakeg...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1460715481000016128</td>\n",
       "      <td>None</td>\n",
       "      <td>[Coach, H24, Lugano, arte, breakfast, coachlug...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1460729770000011520</td>\n",
       "      <td>None</td>\n",
       "      <td>[artist, beatmaker, beats, bern, compo, compos...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1460711375000009216</td>\n",
       "      <td>None</td>\n",
       "      <td>[Congo, Kinshasa, London, Losangeles, Swiss, S...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1460701785000010240</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[aigner, alexandrechristie, bonia, bvlgari, ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1460701785000013056</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[aigner, alexandrechristie, bonia, bvlgari, ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>1460701785000014336</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[aigner, alexandrechristie, bonia, bvlgari, ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1460701785000010496</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[aigner, alexandrechristie, bonia, bvlgari, ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1460764037000000256</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[amillionshades, amillionshadesofcolor, art, a...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>1460701785000014336</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[aigner, alexandrechristie, bonia, bvlgari, ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>1460701786000011520</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[aigner, alexandrechristie, bonia, bvlgari, ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>1460701785000010240</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[aigner, alexandrechristie, bonia, bvlgari, ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>1460701785000011520</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[aigner, alexandrechristie, bonia, bvlgari, ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>1460739842000012544</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[beauty, boy, coachella, cortica, desert, desi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1460711345000000256</td>\n",
       "      <td>None</td>\n",
       "      <td>[beyonce, beyoncetour, celebrity, classic, dan...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1460743002000014592</td>\n",
       "      <td>None</td>\n",
       "      <td>[art, artists, beatmaker, beats, checkmeout, d...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1460745895000007424</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[amazing, americanfood, angusburger, beef, bur...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>1460715880000014592</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[bigroom, deephouse, edm, futurehouse, gallipo...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>1460741697000007424</td>\n",
       "      <td>None</td>\n",
       "      <td>[GADC, breakdance, choreographer, dance, dance...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>1460715881000010240</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[bigroom, deephouse, edm, futurehouse, gallipo...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>1460715881000016128</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[bigroom, deephouse, edm, futurehouse, gallipo...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>1460706130000008960</td>\n",
       "      <td>None</td>\n",
       "      <td>[art, ghostbusters, movie, sculpture, switzerl...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1460715880000016128</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[bigroom, deephouse, edm, futurehouse, gallipo...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>1460707075000010496</td>\n",
       "      <td>None</td>\n",
       "      <td>[aigner, alexandrechristie, bonia, bvlgari, ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>1460696280000013824</td>\n",
       "      <td>None</td>\n",
       "      <td>[aigner, alexandrechristie, bonia, bvlgari, ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1460697972000008192</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>[aigner, alexandrechristie, bonia, bvlgari, ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>1460707075000010240</td>\n",
       "      <td>None</td>\n",
       "      <td>[aigner, alexandrechristie, bonia, bvlgari, ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>1460745493000008704</td>\n",
       "      <td>None</td>\n",
       "      <td>[aroundtheworld, barcelona, beat, brother, dru...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>1460754581000014080</td>\n",
       "      <td>None</td>\n",
       "      <td>[alicechoo, balloonparadise, clubbin, crew, fi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1460731717000015616</td>\n",
       "      <td>None</td>\n",
       "      <td>[cold, enlight, friends, happiness, happy, hap...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>1460722496000002048</td>\n",
       "      <td>None</td>\n",
       "      <td>[banukalenderbebek, bebek, fashion, fashionsta...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>1460738991000002816</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>[abfahrt, charts, club, clubbing, dance, dance...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>1460718525000000256</td>\n",
       "      <td>None</td>\n",
       "      <td>[blackandwhitephotography, coupleforever, drin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>1460742867000016128</td>\n",
       "      <td>None</td>\n",
       "      <td>[action, chase, dslr, filming, fun, gh3, lagom...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>1460740579000015872</td>\n",
       "      <td>None</td>\n",
       "      <td>[bmw, cabriomabrio, chill, cruising, doyouwann...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>1460736830000013568</td>\n",
       "      <td>None</td>\n",
       "      <td>[Transfer, flughafen, halflife3, hyperlapse, s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>1460724451000012288</td>\n",
       "      <td>None</td>\n",
       "      <td>[app, bracelet, dj, gm, handstyle, hiphop, ins...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>1460726695000002816</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[automatic, bespoke, black, crest, diamond, el...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>1460733296000014848</td>\n",
       "      <td>None</td>\n",
       "      <td>[Rolex, cars, defconwatches, fashion, fashiond...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>1460689882000016128</td>\n",
       "      <td>None</td>\n",
       "      <td>[RickyMartin, TBT, boricua, boricuastyle, gewi...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>1460715545000016128</td>\n",
       "      <td>None</td>\n",
       "      <td>[bebop, blues, italianproud, jazz, lucafilastr...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>1460712810000008960</td>\n",
       "      <td>None</td>\n",
       "      <td>[chrishoodstars, echo, echo2016, facebookseite...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>1460706031000016128</td>\n",
       "      <td>None</td>\n",
       "      <td>[NYC, cardiacrhythm, czechrepublic, hhk2015, h...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>1460705070000010752</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>[acting, blackandwhite, chaplinisbackhome, cha...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>1460717192000004352</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[brooklille, charismatic, diamonds, excel, fra...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>1460847535000001024</td>\n",
       "      <td>None</td>\n",
       "      <td>[auch, banken, beatclub, der, die, fast, forma...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>1460740266000008192</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>[arena, blickpunkt, club, deejay, djlife, djpa...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>1460712500000004352</td>\n",
       "      <td>None</td>\n",
       "      <td>[festival, gramatik, marcusmiller, montreuxjaz...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>1460733325000002816</td>\n",
       "      <td>None</td>\n",
       "      <td>[ad, craziness, dope, dxb, emirate, etihad, fu...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>1460890872000000512</td>\n",
       "      <td>None</td>\n",
       "      <td>[arborsnowboards, austria, drunk, ischgl, leti...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>1460740060000008704</td>\n",
       "      <td>None</td>\n",
       "      <td>[and, artistontherise, benjaminamaru, enjoy, e...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>1460737975000000256</td>\n",
       "      <td>None</td>\n",
       "      <td>[blogger, chill, coctail, drink, enjoy, fit, f...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>1460745405000001024</td>\n",
       "      <td>None</td>\n",
       "      <td>[basshouse, comingsoon, dj, futurehouse, happy...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      _id Sentiment  \\\n",
       "66    1460720573000010240  POSITIVE   \n",
       "67    1460720573000010240  POSITIVE   \n",
       "68    1460720574000013056  POSITIVE   \n",
       "89    1460701241000001536      None   \n",
       "118   1460742792000012032  POSITIVE   \n",
       "141   1460757080000015360  POSITIVE   \n",
       "144   1460730835000011008      None   \n",
       "148   1460715627000008192      None   \n",
       "173   1460715481000016128      None   \n",
       "187   1460729770000011520      None   \n",
       "195   1460711375000009216      None   \n",
       "202   1460701785000010240  POSITIVE   \n",
       "207   1460701785000013056  POSITIVE   \n",
       "217   1460701785000014336  POSITIVE   \n",
       "218   1460701785000010496  POSITIVE   \n",
       "221   1460764037000000256  POSITIVE   \n",
       "223   1460701785000014336  POSITIVE   \n",
       "224   1460701786000011520  POSITIVE   \n",
       "227   1460701785000010240  POSITIVE   \n",
       "233   1460701785000011520  POSITIVE   \n",
       "241   1460739842000012544  POSITIVE   \n",
       "251   1460711345000000256      None   \n",
       "255   1460743002000014592      None   \n",
       "258   1460745895000007424  POSITIVE   \n",
       "265   1460715880000014592  POSITIVE   \n",
       "269   1460741697000007424      None   \n",
       "274   1460715881000010240  POSITIVE   \n",
       "281   1460715881000016128  POSITIVE   \n",
       "287   1460706130000008960      None   \n",
       "289   1460715880000016128  POSITIVE   \n",
       "...                   ...       ...   \n",
       "870   1460707075000010496      None   \n",
       "876   1460696280000013824      None   \n",
       "880   1460697972000008192   NEUTRAL   \n",
       "881   1460707075000010240      None   \n",
       "882   1460745493000008704      None   \n",
       "886   1460754581000014080      None   \n",
       "889   1460731717000015616      None   \n",
       "904   1460722496000002048      None   \n",
       "920   1460738991000002816   NEUTRAL   \n",
       "929   1460718525000000256      None   \n",
       "942   1460742867000016128      None   \n",
       "955   1460740579000015872      None   \n",
       "963   1460736830000013568      None   \n",
       "972   1460724451000012288      None   \n",
       "978   1460726695000002816  POSITIVE   \n",
       "988   1460733296000014848      None   \n",
       "1016  1460689882000016128      None   \n",
       "1019  1460715545000016128      None   \n",
       "1034  1460712810000008960      None   \n",
       "1097  1460706031000016128      None   \n",
       "1102  1460705070000010752   NEUTRAL   \n",
       "1130  1460717192000004352  POSITIVE   \n",
       "1136  1460847535000001024      None   \n",
       "1142  1460740266000008192   NEUTRAL   \n",
       "1149  1460712500000004352      None   \n",
       "1167  1460733325000002816      None   \n",
       "1175  1460890872000000512      None   \n",
       "1204  1460740060000008704      None   \n",
       "1206  1460737975000000256      None   \n",
       "1222  1460745405000001024      None   \n",
       "\n",
       "                                                   Tags  Food  Sports  Nature  \\\n",
       "66    [and, ataxia, booyah, club, dancefloor, dims, ...     0       1       0   \n",
       "67    [and, ataxia, booyah, club, dancefloor, dims, ...     0       1       0   \n",
       "68    [and, ataxia, booyah, club, dancefloor, dims, ...     0       1       0   \n",
       "89    [Bar, George, Grill, Restaurant, afterwork, be...     3       1       0   \n",
       "118   [abstract, actor, architecture, awesome, bouti...     0       2       0   \n",
       "141   [brennereiclub, captainsclub, dasschwarzeschaf...     0       4       0   \n",
       "144   [alps, interlaken, movie, selca, selfie, skydi...     0       1       0   \n",
       "148   [feelgood, fridaymorning, keeponrunning, lakeg...     0       1       0   \n",
       "173   [Coach, H24, Lugano, arte, breakfast, coachlug...     1       1       1   \n",
       "187   [artist, beatmaker, beats, bern, compo, compos...     0       5       1   \n",
       "195   [Congo, Kinshasa, London, Losangeles, Swiss, S...     0       1       0   \n",
       "202   [aigner, alexandrechristie, bonia, bvlgari, ca...     0       1       0   \n",
       "207   [aigner, alexandrechristie, bonia, bvlgari, ca...     0       1       0   \n",
       "217   [aigner, alexandrechristie, bonia, bvlgari, ca...     0       1       0   \n",
       "218   [aigner, alexandrechristie, bonia, bvlgari, ca...     0       1       0   \n",
       "221   [amillionshades, amillionshadesofcolor, art, a...     0       2       0   \n",
       "223   [aigner, alexandrechristie, bonia, bvlgari, ca...     0       1       0   \n",
       "224   [aigner, alexandrechristie, bonia, bvlgari, ca...     0       1       0   \n",
       "227   [aigner, alexandrechristie, bonia, bvlgari, ca...     0       1       0   \n",
       "233   [aigner, alexandrechristie, bonia, bvlgari, ca...     0       1       0   \n",
       "241   [beauty, boy, coachella, cortica, desert, desi...     0       1       0   \n",
       "251   [beyonce, beyoncetour, celebrity, classic, dan...     0       2       0   \n",
       "255   [art, artists, beatmaker, beats, checkmeout, d...     0       4       0   \n",
       "258   [amazing, americanfood, angusburger, beef, bur...     4       1       0   \n",
       "265   [bigroom, deephouse, edm, futurehouse, gallipo...     0       2       0   \n",
       "269   [GADC, breakdance, choreographer, dance, dance...     0       1       0   \n",
       "274   [bigroom, deephouse, edm, futurehouse, gallipo...     0       2       0   \n",
       "281   [bigroom, deephouse, edm, futurehouse, gallipo...     0       2       0   \n",
       "287   [art, ghostbusters, movie, sculpture, switzerl...     0       1       0   \n",
       "289   [bigroom, deephouse, edm, futurehouse, gallipo...     0       2       0   \n",
       "...                                                 ...   ...     ...     ...   \n",
       "870   [aigner, alexandrechristie, bonia, bvlgari, ca...     0       1       0   \n",
       "876   [aigner, alexandrechristie, bonia, bvlgari, ca...     0       1       0   \n",
       "880   [aigner, alexandrechristie, bonia, bvlgari, ca...     0       1       0   \n",
       "881   [aigner, alexandrechristie, bonia, bvlgari, ca...     0       1       0   \n",
       "882   [aroundtheworld, barcelona, beat, brother, dru...     0       2       0   \n",
       "886   [alicechoo, balloonparadise, clubbin, crew, fi...     0       1       0   \n",
       "889   [cold, enlight, friends, happiness, happy, hap...     0       1       0   \n",
       "904   [banukalenderbebek, bebek, fashion, fashionsta...     0       2       0   \n",
       "920   [abfahrt, charts, club, clubbing, dance, dance...     0       2       0   \n",
       "929   [blackandwhitephotography, coupleforever, drin...     1       1       0   \n",
       "942   [action, chase, dslr, filming, fun, gh3, lagom...     0       1       0   \n",
       "955   [bmw, cabriomabrio, chill, cruising, doyouwann...     0       1       0   \n",
       "963   [Transfer, flughafen, halflife3, hyperlapse, s...     0       1       0   \n",
       "972   [app, bracelet, dj, gm, handstyle, hiphop, ins...     0       3       0   \n",
       "978   [automatic, bespoke, black, crest, diamond, el...     0       1       1   \n",
       "988   [Rolex, cars, defconwatches, fashion, fashiond...     0       1       0   \n",
       "1016  [RickyMartin, TBT, boricua, boricuastyle, gewi...     0       2       0   \n",
       "1019  [bebop, blues, italianproud, jazz, lucafilastr...     0       1       0   \n",
       "1034  [chrishoodstars, echo, echo2016, facebookseite...     0       1       0   \n",
       "1097  [NYC, cardiacrhythm, czechrepublic, hhk2015, h...     0       1       0   \n",
       "1102  [acting, blackandwhite, chaplinisbackhome, cha...     0       1       0   \n",
       "1130  [brooklille, charismatic, diamonds, excel, fra...     0       1       0   \n",
       "1136  [auch, banken, beatclub, der, die, fast, forma...     0       1       0   \n",
       "1142  [arena, blickpunkt, club, deejay, djlife, djpa...     0       2       0   \n",
       "1149  [festival, gramatik, marcusmiller, montreuxjaz...     0       1       0   \n",
       "1167  [ad, craziness, dope, dxb, emirate, etihad, fu...     0       2       0   \n",
       "1175  [arborsnowboards, austria, drunk, ischgl, leti...     0       1       0   \n",
       "1204  [and, artistontherise, benjaminamaru, enjoy, e...     0       2       0   \n",
       "1206  [blogger, chill, coctail, drink, enjoy, fit, f...     1       1       0   \n",
       "1222  [basshouse, comingsoon, dj, futurehouse, happy...     0       3       0   \n",
       "\n",
       "      Culture  Travel  \n",
       "66          0       2  \n",
       "67          0       2  \n",
       "68          0       2  \n",
       "89          0       2  \n",
       "118         0       0  \n",
       "141         0       0  \n",
       "144         0       0  \n",
       "148         1       0  \n",
       "173         1       0  \n",
       "187         0       0  \n",
       "195         0       0  \n",
       "202         0       0  \n",
       "207         0       0  \n",
       "217         0       0  \n",
       "218         0       0  \n",
       "221         0       0  \n",
       "223         0       0  \n",
       "224         0       0  \n",
       "227         0       0  \n",
       "233         0       0  \n",
       "241         0       2  \n",
       "251         0       0  \n",
       "255         0       0  \n",
       "258         0       0  \n",
       "265         0       0  \n",
       "269         0       0  \n",
       "274         0       0  \n",
       "281         0       0  \n",
       "287         0       0  \n",
       "289         0       0  \n",
       "...       ...     ...  \n",
       "870         0       0  \n",
       "876         0       0  \n",
       "880         0       0  \n",
       "881         0       0  \n",
       "882         0       0  \n",
       "886         0       0  \n",
       "889         0       1  \n",
       "904         0       0  \n",
       "920         0       0  \n",
       "929         0       0  \n",
       "942         1       0  \n",
       "955         0       0  \n",
       "963         0       0  \n",
       "972         0       0  \n",
       "978         0       0  \n",
       "988         0       0  \n",
       "1016        0       0  \n",
       "1019        1       0  \n",
       "1034        0       0  \n",
       "1097        0       0  \n",
       "1102        0       0  \n",
       "1130        0       0  \n",
       "1136        0       1  \n",
       "1142        0       0  \n",
       "1149        0       0  \n",
       "1167        0       0  \n",
       "1175        0       1  \n",
       "1204        0       0  \n",
       "1206        1       2  \n",
       "1222        0       0  \n",
       "\n",
       "[117 rows x 8 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Sports > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total is 1224, now I have 537, which is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "58 + 117 + 92 + 82 + 188"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing General Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Getting one single city from list of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CITY_LIST = df_geo.city.values # gets more complicated as df_geo gets more complicated\n",
    "\n",
    "def extract_city(tag_list):\n",
    "    # geo_map['city]\n",
    "    return next((city for city in tag_list if city in CITY_LIST), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_city = df_extracted.Tags.apply(extract_city).to_frame('City')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_extracted = df_extracted.join(df_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "geo_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_map = {'zurich':'ZH','geneva':'GE','lausanne':'VD','zermatt':'VS','bern':'BE',\n",
    "           'basel':'BS','geneve':'GE','winterthur':'ZH','luzern':'LU','lucerne':'LU',\n",
    "          'st-gallen':'SG','lugano':'TI'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Mapping City to Canton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_extracted['Canton'] = df_extracted['City'].map(geo_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_extracted.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_extracted.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 123 out of 1225 have both sentiment and canton. It's just 10% now. We need to get more sentiment using CNN and get more geolocation by using a more comprehensive dictionary of cities and cantons. The current manual list fills about 33% of total locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_viz = df_extracted.dropna()\n",
    "df_viz['Sentiment_Val'] = df_viz['Sentiment'].replace(sent_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_map = {'NEUTRAL': 0, 'POSITIVE':1, 'NEGATIVE':-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_viz = pd.DataFrame(df_viz.groupby('Canton').mean()['Sentiment_Val'])\n",
    "df_viz.reset_index(inplace=1) \n",
    "df_viz.columns = ['Canton', 'Sentiment_Val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "swiss_cantons = ['AG', 'AI', 'AR', 'BE', 'BL', 'BS', 'FR', 'GE', 'GL', 'GR', 'JU',\n",
    "'LU', 'NE', 'NW', 'OW', 'SG', 'SH', 'SO', 'SZ', 'TG', 'TI', 'UR',\n",
    "'VD', 'VS', 'ZG', 'ZH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_viz = pd.merge(df_viz, pd.Series(swiss_cantons).to_frame('Canton'), how='outer',on='Canton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_viz.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Swiss Sentiment Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build the Scale with the Legend\n",
    "Legend = folium.colormap.linear.YlGn.scale( 0, 1 )\n",
    "Legend = Legend.to_step(10)\n",
    "Legend.caption = 'Happiness of Swiss Cantons'\n",
    "Legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load geojson data\n",
    "geo_json_data = json.load(open(r'Data/ch-cantons.geojson.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "canton_dict = df_viz.set_index('Canton')['Sentiment_Val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "swiss_map = folium.Map(location=[47, 8],tiles='cartodbpositron', zoom_start=8)\n",
    "\n",
    "folium.GeoJson(\n",
    "    geo_json_data,\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': Legend(canton_dict[feature['id']]),\n",
    "        'color': 'black',\n",
    "        'weight': 1,\n",
    "        'dashArray': '1',\n",
    "        'fillOpacity': 0.7,\n",
    "    }\n",
    ").add_to(swiss_map)\n",
    "\n",
    "Legend.add_to(swiss_map)\n",
    "\n",
    "swiss_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
