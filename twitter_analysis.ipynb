{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting and saving the cleaned twitter data\n",
    "* We get the necessary columns for the twitter data from the  .json files by running the code on the cluster and saving the dataframes as parquet.\n",
    "* The code to get the data is in cleaned_twitter.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import pyspark.sql\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "conf = SparkConf().setAppName(\"ADA-gcl\")\n",
    "#sc = SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)\n",
    "#sqlContext.setConf(\"spark.sql.parquet.compression.codec\", \"snappy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the paqueret data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_path = 'file:///home/kirtan/Academics/EPFL/sem1/ADA/ADA-Project/Data/'\n",
    "files = os.listdir('Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_jan = 'file:///home/kirtan/Academics/EPFL/sem1/ADA/ADA-Project/Data/twitter_cleaned_jan.parquet'\n",
    "df = sqlContext.read.parquet(path_jan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_twitter = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for f in tqdm(files[1:]):\n",
    "    temp = sqlContext.read.parquet(base_path + f)\n",
    "    df_twitter = df_twitter.unionAll(temp)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Runs out of memory for me, but you can try. Function to convert df to pandas\n",
    "#final = df_twitter.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10534806"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of tweets\n",
    "df_twitter.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Removing those which do not have a sentiment\n",
    "t1 = df_twitter.filter(df.sentiment != 'null')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9797616"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(language='en', count=4129564),\n",
       " Row(language='de', count=2288993),\n",
       " Row(language='fr', count=2090395),\n",
       " Row(language='es', count=735317),\n",
       " Row(language='it', count=242370),\n",
       " Row(language='pt', count=60368),\n",
       " Row(language='ja', count=28238),\n",
       " Row(language='sv', count=24039),\n",
       " Row(language='ar', count=22622),\n",
       " Row(language='in', count=22321),\n",
       " Row(language='tr', count=20801),\n",
       " Row(language='da', count=16726),\n",
       " Row(language='tl', count=15504),\n",
       " Row(language='ht', count=15075),\n",
       " Row(language='pl', count=13937),\n",
       " Row(language='nl', count=12099),\n",
       " Row(language='no', count=10216),\n",
       " Row(language='ru', count=9812),\n",
       " Row(language='fi', count=8950),\n",
       " Row(language='et', count=8065),\n",
       " Row(language='hi', count=4597),\n",
       " Row(language='ko', count=4335),\n",
       " Row(language='el', count=4003),\n",
       " Row(language='lt', count=1776),\n",
       " Row(language='hu', count=1165),\n",
       " Row(language='sl', count=926),\n",
       " Row(language='lv', count=913),\n",
       " Row(language='uk', count=765),\n",
       " Row(language='zh', count=747),\n",
       " Row(language='is', count=691),\n",
       " Row(language='th', count=444),\n",
       " Row(language='ro', count=379),\n",
       " Row(language='vi', count=335),\n",
       " Row(language='cy', count=203),\n",
       " Row(language='eu', count=175),\n",
       " Row(language='bg', count=166),\n",
       " Row(language='ur', count=130),\n",
       " Row(language='cs', count=119),\n",
       " Row(language='fa', count=81),\n",
       " Row(language='ta', count=56),\n",
       " Row(language='iw', count=52),\n",
       " Row(language='ml', count=41),\n",
       " Row(language='ne', count=30),\n",
       " Row(language='sr', count=28),\n",
       " Row(language='si', count=17),\n",
       " Row(language='te', count=4),\n",
       " Row(language='hy', count=4),\n",
       " Row(language='pa', count=4),\n",
       " Row(language='mr', count=3),\n",
       " Row(language='my', count=3),\n",
       " Row(language='am', count=3),\n",
       " Row(language='bo', count=3),\n",
       " Row(language='ka', count=3),\n",
       " Row(language='bn', count=1),\n",
       " Row(language='dv', count=1),\n",
       " Row(language='lo', count=1)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "# See main languages\n",
    "t1.groupBy(['language']).count().sort(col(\"count\").desc()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keeping only the major languages\n",
    "t2 = t1.where(col(\"language\").isin({\"en\", \"de\", \"fr\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8508952"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.count()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
